# Objective

Here, we will primary discuss Makefile / CMake / Meson build systems

## Common terms

![Compilation-Process-in-C](https://github.com/user-attachments/assets/bf663f02-85f2-4a18-bc71-6309c17fdbe9)

Compiler
- A compiler is a software tool that translates high-level programming code written in languages like C, C++, or Java into machine-readable binary code (object code) that a computer's processor can understand and execute. The process typically involves several stages:
  - Preprocessing: \
    In this stage, the preprocessor (part of the compiler) handles directives such as #include and #define, and expands them accordingly.
  - Compilation: \
    The compiler translates the preprocessed source code into assembly code or an intermediate representation specific to the target platform.
  - Assembly: \
    The assembly code is translated into machine code by the assembler. This step may be included in the compilation process or may be a separate step depending on the compiler.
  - Linking (optional): \
    In some cases, the compiler also performs linking, which involves combining object files and libraries into an executable file or shared library.

Linker:
- A linker is a separate program or component of the compiler toolchain that takes one or more object files generated by the compiler and combines them into a single executable file or library. The linker resolves references between different parts of the program and ensures that all necessary functions and data are correctly linked together. Key tasks of the linker include:
  - Symbol Resolution: \
    The linker resolves symbolic references between different object files and libraries. It ensures that all functions and variables referenced in one part of the program are defined elsewhere in the program or in external libraries.
  - Address Binding: \
    The linker assigns memory addresses to symbols (functions, variables, etc.) within the program, determining where they will be located in memory when the program is loaded and executed.
  - Executable Generation: \
    The linker combines the object files and libraries into a single executable file or shared library that can be executed by the operating system.

Loader:
- The loader is a component of the operating system responsible for loading executable files into memory and preparing them for execution. When a program is executed, the loader performs the following tasks:
  - Memory Allocation: \
    The loader allocates memory space for the program in the computer's memory (RAM), loading the program's code, data, and stack segments into memory.
  - Symbol Resolution: \
    If the program makes use of dynamic linking, the loader resolves any unresolved symbols by loading the necessary libraries into memory and linking them with the program.
  - Relocation: \
    The loader performs any necessary address relocation to ensure that the program's code and data segments are correctly mapped to the allocated memory addresses.
  - Initialization: \
    The loader initializes the program's execution environment, setting up the program's entry point and any required runtime environment variables.
  - Transfer of Control: \
    Finally, the loader transfers control to the program's entry point, starting its execution.

Dynamic Linking:
- Dynamic linking is a process where the linking of libraries to an executable occurs **at runtime**, rather than at compile time. Instead of including the code from libraries directly into the executable, the necessary libraries are referenced and linked when the program is loaded into memory or executed.
- Advantages of Dynamic Linking:
  - Reduced Memory Usage: \
    Since libraries are not directly included in the executable, memory usage is reduced because the libraries are shared among multiple processes.
  - Flexibility: \
    Libraries can be updated or replaced without recompiling the entire program. This makes maintenance easier and allows for bug fixes and feature enhancements to be deployed more efficiently.
  - Faster Build Times: \
    By not including the library code in the executable, the build process is faster, especially for large projects with many dependencies.
  - Simplified Deployment: \
    Executables are smaller in size since they don't contain the entire library code, making deployment easier and faster.

Dynamic Loading:
- Dynamic loading is the process of loading libraries or modules into a program's address space **at runtime**, allowing the program to access their functionality when needed. Unlike static loading, where all dependencies are loaded when the program starts, dynamic loading allows for more selective loading of libraries or modules.
- Advantages of Dynamic Loading:
  - Lazy Loading: \
    Libraries are only loaded into memory when they are explicitly requested by the program. This can reduce startup time and memory usage, especially for large applications with many dependencies.
  - On-Demand Functionality: \
    Dynamic loading enables programs to load libraries or modules on-demand, allowing them to access specific functionality when needed. This can improve performance and resource utilization by avoiding unnecessary loading of unused code.
  - Plugin Support: \
    Dynamic loading is commonly used in plugin-based architectures, where plugins or extensions can be dynamically loaded and unloaded at runtime, allowing for dynamic customization and extensibility of the application.
  - Hot Reloading: \
    In development environments, dynamic loading enables hot reloading, where code changes can be applied to a running application without restarting it, speeding up the development and testing process.

Shared Objects (.so):
- Operating System: Unix-like systems (e.g., Linux).
- File Extension: .so.
- Functionality: \
  Shared Objects can be loaded and used by multiple programs at runtime. They are common in Linux and other Unix-based systems. These libraries can be linked dynamically, allowing the system to load them as needed.
- Advantages:
  - Reduce the memory footprint and simplify updates.
  - Promotes code reuse and modular design.

Dynamic Link Libraries (.dll):
- Operating System: Windows.
- File Extension: .dll.
- Functionality: \
  DLLs can contain code, data, and resources (such as images) that can be used by multiple programs simultaneously. They are loaded into memory only once and are dynamically linked, meaning they are loaded by programs when needed at runtime.
- Advantages:
  - Reduces the memory footprint since the code is shared among multiple programs.
  - Simplifies updates; only the DLL needs to be updated instead of every program that uses it.
  - Enables modular program design.

Sample of Dynamic linking or loading in C:
[dynamic_linking_loading.md](./dynamic_linking_loading.md)

Reference:
https://www.geeksforgeeks.org/compiling-a-c-program-behind-the-scenes/

## Makefile VS CMake VS Meson VS Ninja VS Autotools

### Brief History
- Makefile:
  - Origin: Developed in 1976 by Stuart Feldman at Bell Labs.
  - Purpose: Automates the build process by defining a set of tasks to be executed.
  - Usage: Widely used in Unix-based systems for compiling and linking programs.
- Autotools:
  - Origin: Introduced in the early 1990s.
  - Components: Includes Autoconf, Automake, and Libtool.
  - Purpose: Provides a suite of tools to make source code packages portable to many Unix-like systems.
- CMake:
  - Origin: Created in 2000 by Kitware.
  - Purpose: A cross-platform tool that generates native build scripts for various platforms.
  - Usage: Popular in open-source projects and supports multiple build systems like Make and Ninja.
- Ninja:
  - Origin: Developed by Evan Martin in 2012.
  - Purpose: Focuses on speed and efficiency, designed to run builds as fast as possible.
  - Usage: Often used as a backend for CMake.
- Meson:
  - Origin: Introduced in 2012 by Jussi Pakkanen.
  - Purpose: Aims to provide a fast and user-friendly build system.
  - Usage: Known for its simplicity and speed, often used with Ninja as the backend.
- Popularity Comparison:
  - Makefile: Still widely used, especially in legacy systems and simple projects. Its simplicity and direct control over the build process make it a staple in many Unix environments.
  - Autotools: While powerful and flexible, it has a steep learning curve and is considered somewhat outdated. Its usage has declined in favor of more modern tools.
  - CMake: Extremely popular due to its cross-platform capabilities and support for various IDEs and build systems. It is the go-to choice for many open-source projects.
  - Ninja: Known for its speed, it is often used in conjunction with CMake. Its popularity is growing, especially in projects where build speed is critical.
  - Meson: Gaining traction for its simplicity and performance. It is becoming a popular choice for new projects, particularly in the open-source community.
  In terms of current popularity, CMake and Ninja are leading the pack, with Meson quickly catching up12Makefile remains a fundamental tool, especially in Unix environments, while Autotools is less favored due to its complexity and age


### Will Makefile script be different from OS to OS ?

Yes, Makefiles can vary from one operating system to another, primarily due to differences in how commands are executed, the syntax of shell commands, and the availability of certain utilities and tools. Here are some key points to consider:
- Shell Commands and Syntax: \
  Makefiles typically contain shell commands to perform actions like compiling source code, linking binaries, or executing scripts. The syntax and behavior of these commands can vary between different shells (e.g., Bash, CMD in Windows, PowerShell) and operating systems.
- Tool Availability:
  - Makefiles often rely on external tools and utilities such as compilers (e.g., GCC, Clang), linkers, archivers, and other system-specific tools. The availability and paths of these tools can vary between operating systems.
  - Different operating systems may have different default locations for these tools, or they may require different installation procedures.
Platform-Specific Directives:
  - Makefiles might include platform-specific directives or conditionals (ifdef, ifeq, etc.) to handle differences between operating systems.
  - These directives can be used to set different compiler flags, include different libraries, or adjust paths based on the operating system where the Makefile is being used.
- File Path Handling: \
  Operating systems have different conventions for file paths (e.g., using forward slashes / in Unix-like systems versus backward slashes \ in Windows). Makefiles need to handle these differences appropriately, especially when dealing with paths to source files, output directories, etc.
- Default Rules and Variables:
  - Default rules (implicit rules) and variables (automatic variables) used in Makefiles can also differ between operating systems. While many conventions are standard across POSIX-compliant systems, specific implementations and behaviors can vary.
  - To mitigate these differences and ensure portability of Makefiles across different operating systems, developers often use conditional statements based on environment variables or predefined macros to adapt the Makefile's behavior to different platforms.
